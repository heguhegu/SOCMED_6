{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo_day_word2vec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQte1SwsyuEP",
        "outputId": "a5610c00-797b-435b-cfd0-04f4ffc383f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "metadata": {
        "id": "AA16XSCQ-EpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Training/DTS_Tensorflow/demo/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0sjHVpW-NwK",
        "outputId": "13be08dc-d103-4d96-e927-78c92f2d0a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Training/DTS_Tensorflow/demo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
        "!gunzip cc.en.300.vec.gz\n",
        "!rm -rf gunzip cc.en.300.vec.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHLHw8blDJgx",
        "outputId": "d7130dc3-3bea-4edf-cab9-869d1e67b032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-26 05:48:47--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1325960915 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.en.300.vec.gz’\n",
            "\n",
            "cc.en.300.vec.gz    100%[===================>]   1.23G  34.2MB/s    in 70s     \n",
            "\n",
            "2022-07-26 05:49:57 (18.1 MB/s) - ‘cc.en.300.vec.gz’ saved [1325960915/1325960915]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('tweets.csv')"
      ],
      "metadata": {
        "id": "1PIqk0L9-PqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_URL(text):\n",
        "    url = re.compile(r'https?://\\S+')\n",
        "    return url.sub(r' httpsmark ', text)\n",
        "\n",
        "\n",
        "def remove_html(text):\n",
        "    html = re.compile(r'<.*?>')\n",
        "    return html.sub(r'', text)\n",
        "\n",
        "\n",
        "def remove_atsymbol(text):\n",
        "    name = re.compile(r'@\\S+')\n",
        "    return name.sub(r' atsymbol ', text)\n",
        "\n",
        "\n",
        "def remove_hashtag(text):\n",
        "    hashtag = re.compile(r'#')\n",
        "    return hashtag.sub(r' hashtag ', text)\n",
        "\n",
        "\n",
        "def remove_exclamation(text):\n",
        "    exclamation = re.compile(r'!')\n",
        "    return exclamation.sub(r' exclamation ', text)\n",
        "\n",
        "\n",
        "def remove_question(text):\n",
        "    question = re.compile(r'?')\n",
        "    return question.sub(r' question ', text)\n",
        "\n",
        "\n",
        "def remove_punc(text):\n",
        "    return text.translate(str.maketrans('','',string.punctuation))\n",
        "\n",
        "\n",
        "def remove_number(text):\n",
        "    number = re.compile(r'\\d+')\n",
        "    return number.sub(r' number ', text)\n",
        "\n",
        "\n",
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\U0001f926-\\U0001f937\"\n",
        "                               u\"\\U00010000-\\U0010ffff\"\n",
        "                               u\"\\u2640-\\u2642\"\n",
        "                               u\"\\u2600-\\u2B55\"\n",
        "                               u\"\\u200d\"\n",
        "                               u\"\\u23cf\"\n",
        "                               u\"\\u23e9\"\n",
        "                               u\"\\u231a\"\n",
        "                               u\"\\ufe0f\"  # dingbats\n",
        "                               u\"\\u3030\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r' emoji ', string)"
      ],
      "metadata": {
        "id": "4zLXhpyb-UN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['text'] = df['text'].str.lower()\n",
        "df['text'] = df['text'].apply(lambda text: remove_URL(text))\n",
        "df['text'] = df['text'].apply(lambda text: remove_html(text))\n",
        "df['text'] = df['text'].apply(lambda text: remove_atsymbol(text))\n",
        "df['text'] = df['text'].apply(lambda text: remove_hashtag(text))\n",
        "df['text'] = df['text'].apply(lambda text: remove_exclamation(text))\n",
        "df['text'] = df['text'].apply(lambda text: remove_punc(text))\n",
        "df['text'] = df['text'].apply(lambda text: remove_number(text))\n",
        "df['text'] = df['text'].apply(lambda text: remove_emoji(text))"
      ],
      "metadata": {
        "id": "YtvoRuhL-VYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tk = Tokenizer(lower=True, filters='')\n",
        "tk.fit_on_texts(df.text)\n",
        "\n",
        "max_len = 120 # Calculate as max in dataset see 1.data_process.ipynb\n",
        "train_tokenized = tk.texts_to_sequences(df.text)\n",
        "X = pad_sequences(train_tokenized, maxlen=max_len)"
      ],
      "metadata": {
        "id": "LpaTiwJxFTe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,df.target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "QcsHrmsW-XiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 300\n",
        "max_features = 30000\n",
        "\n",
        "def get_coefs(word,*arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(\"cc.en.300.vec\"))\n",
        "word_index = tk.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "-QJnRKiY-ZvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam = Adam(learning_rate=0.001)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape = (max_len,)),\n",
        "    tf.keras.layers.Embedding(nb_words+1, embed_size, weights = [embedding_matrix], trainable=False),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,recurrent_dropout=0.4)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss=SparseCategoricalCrossentropy(),optimizer=adam,metrics=[SparseCategoricalAccuracy()])\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBe85mqFG1Z-",
        "outputId": "992b138d-ecda-468c-d419-e771911cff74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 120, 300)          7230900   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              186880    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,421,974\n",
            "Trainable params: 191,074\n",
            "Non-trainable params: 7,230,900\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callback = [EarlyStopping(\n",
        "    monitor='val_sparse_categorical_accuracy',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    min_delta=0.01\n",
        "), \n",
        "ModelCheckpoint(\n",
        "    filepath='checkpoint_model_word2vec/',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_sparse_categorical_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "]"
      ],
      "metadata": {
        "id": "c_xy7_ob_C41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "history = model.fit(X_train,y_train,batch_size=512,epochs=20, validation_split=0.2,callbacks=callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcEGnW4B-mXn",
        "outputId": "e6c63146-c7e8-44d0-9312-599001717ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "15/15 [==============================] - 47s 3s/step - loss: 0.5840 - sparse_categorical_accuracy: 0.7610 - val_loss: 0.4796 - val_sparse_categorical_accuracy: 0.8121\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 47s 3s/step - loss: 0.4554 - sparse_categorical_accuracy: 0.8109 - val_loss: 0.4266 - val_sparse_categorical_accuracy: 0.8115\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 45s 3s/step - loss: 0.4063 - sparse_categorical_accuracy: 0.8169 - val_loss: 0.3913 - val_sparse_categorical_accuracy: 0.8412\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 41s 3s/step - loss: 0.3656 - sparse_categorical_accuracy: 0.8492 - val_loss: 0.3566 - val_sparse_categorical_accuracy: 0.8549\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 37s 2s/step - loss: 0.3329 - sparse_categorical_accuracy: 0.8678 - val_loss: 0.3406 - val_sparse_categorical_accuracy: 0.8648\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 34s 2s/step - loss: 0.3140 - sparse_categorical_accuracy: 0.8730 - val_loss: 0.3263 - val_sparse_categorical_accuracy: 0.8654\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 43s 3s/step - loss: 0.3048 - sparse_categorical_accuracy: 0.8778 - val_loss: 0.3237 - val_sparse_categorical_accuracy: 0.8703\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 41s 3s/step - loss: 0.2971 - sparse_categorical_accuracy: 0.8825 - val_loss: 0.3178 - val_sparse_categorical_accuracy: 0.8720\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 34s 2s/step - loss: 0.2925 - sparse_categorical_accuracy: 0.8843 - val_loss: 0.3148 - val_sparse_categorical_accuracy: 0.8786\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 33s 2s/step - loss: 0.2904 - sparse_categorical_accuracy: 0.8866 - val_loss: 0.3136 - val_sparse_categorical_accuracy: 0.8786\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 35s 2s/step - loss: 0.2825 - sparse_categorical_accuracy: 0.8899 - val_loss: 0.3140 - val_sparse_categorical_accuracy: 0.8786\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 38s 3s/step - loss: 0.2779 - sparse_categorical_accuracy: 0.8913 - val_loss: 0.3107 - val_sparse_categorical_accuracy: 0.8791\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 44s 3s/step - loss: 0.2745 - sparse_categorical_accuracy: 0.8925 - val_loss: 0.3064 - val_sparse_categorical_accuracy: 0.8813\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 35s 2s/step - loss: 0.2695 - sparse_categorical_accuracy: 0.8938 - val_loss: 0.3051 - val_sparse_categorical_accuracy: 0.8780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(f'checkpoint_model_word2vec/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qte44O6zHrka",
        "outputId": "e026607f-bad1-48ac-aa6b-28bede8e2f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff79da86ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klK69v29KELQ",
        "outputId": "0dcd7520-4184-479e-c28c-7c13c01e4955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72/72 [==============================] - 11s 156ms/step - loss: 0.2819 - sparse_categorical_accuracy: 0.8861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2818973660469055, 0.8861038088798523]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y0kqm1TvKGL1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}